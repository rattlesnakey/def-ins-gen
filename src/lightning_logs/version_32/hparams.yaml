accumulate_grad_batches: 1
adafactor: false
adam_epsilon: 1.0e-08
amp_backend: native
amp_level: O2
attention_dropout: null
auto_gpus: false
auto_lr: false
auto_lr_find: false
auto_scale_batch_size: false
auto_select_gpus: false
beams_group: 1
beams_penalty: 1.0
benchmark: false
cache_dir: ''
check_val_every_n_epoch: 1
checkpoint_callback: true
config_name: ''
data_dir: ../data/wordnet/
decoder_layerdrop: null
default_root_dir: null
deterministic: false
distributed_backend: null
do_predict: true
do_train: true
dropout: null
early_stop_callback: false
early_stopping_patience: 5
encoder_layerdrop: null
eval_batch_size: 1
fast_dev_run: false
fp16: false
fp16_opt_level: O2
freeze_embeds: false
freeze_encoder: false
gpus: 0
gradient_clip_val: 0
learning_rate: 0.0003
limit_test_batches: 1.0
limit_train_batches: 1.0
limit_val_batches: 1.0
log_gpu_memory: null
log_save_interval: 100
logger: true
logger_name: default
lr_scheduler: linear
max_epochs: 1
max_source_length: 120
max_steps: null
max_target_length: 120
min_epochs: 1
min_steps: null
model_name_or_path: t5-small
n_test: -1
n_train: -1
n_val: 500
num_beams: 100
num_nodes: 1
num_processes: 1
num_sanity_val_steps: 2
num_workers: 1
output_dir: ../output/wordnet-ins-gen-and-def-gen-prompt3-1-3e-4/
overfit_batches: 0.0
overfit_pct: null
precision: 32
prepare_data_per_node: true
process_position: 0
profiler: null
progress_bar_refresh_rate: 1
prompt: prompt3
reload_dataloaders_every_epoch: false
replace_sampler_ddp: true
resume_ckpt: false
resume_from_checkpoint: null
row_log_interval: 50
sample: 2
seed: 42
self_ref: true
sync_batchnorm: false
task: ins-gen-and-def-gen
terminate_on_nan: false
test_dataset: test
test_max_target_length: 150
test_percent_check: null
tokenizer_name: null
track_grad_norm: -1
train_batch_size: 1
train_percent_check: null
truncated_bptt_steps: null
val_check_interval: 1.0
val_max_target_length: 150
val_percent_check: null
warmup_steps: 0
weight_decay: 0.0
weights_save_path: null
weights_summary: top
